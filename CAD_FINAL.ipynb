{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['캐나다', '2019.11.21', '883.35', '900.75', '865.95', '892.18', '874.52', '896.60', '873.58']\n",
      "['캐나다', '2019.11.20', '879.28', '896.60', '861.96', '888.07', '870.49', '892.46', '869.55']\n",
      "['캐나다', '2019.11.19', '883.28', '900.68', '865.88', '892.11', '874.45', '896.52', '873.51']\n",
      "['캐나다', '2019.11.18', '881.65', '899.01', '864.29', '890.46', '872.84', '894.87', '871.90']\n",
      "['캐나다', '2019.11.15', '880.92', '898.27', '863.57', '889.72', '872.12', '894.13', '871.18']\n",
      "['캐나다', '2019.11.14', '882.40', '899.78', '865.02', '891.22', '873.58', '895.63', '872.64']\n",
      "['캐나다', '2019.11.13', '881.74', '899.11', '864.37', '890.55', '872.93', '894.96', '871.99']\n",
      "['캐나다', '2019.11.12', '878.01', '895.30', '860.72', '886.79', '869.23', '891.18', '868.29']\n",
      "['캐나다', '2019.11.11', '881.49', '898.85', '864.13', '890.30', '872.68', '894.71', '871.74']\n",
      "['캐나다', '2019.11.08', '876.86', '894.13', '859.59', '885.62', '868.10', '890.01', '867.16']\n",
      "['캐나다', '2019.11.07', '878.39', '895.69', '861.09', '887.17', '869.61', '891.56', '868.67']\n",
      "['캐나다', '2019.11.06', '880.25', '897.59', '862.91', '889.05', '871.45', '893.45', '870.51']\n",
      "['캐나다', '2019.11.05', '881.10', '898.45', '863.75', '889.91', '872.29', '894.31', '871.35']\n",
      "['캐나다', '2019.11.04', '882.21', '899.58', '864.84', '891.03', '873.39', '895.44', '872.45']\n",
      "['캐나다', '2019.11.01', '886.54', '904.00', '869.08', '895.40', '877.68', '899.83', '876.73']\n",
      "['캐나다', '2019.10.31', '887.55', '905.03', '870.07', '896.42', '878.68', '900.86', '877.73']\n",
      "['캐나다', '2019.10.30', '892.26', '909.83', '874.69', '901.18', '883.34', '905.64', '882.39']\n",
      "['캐나다', '2019.10.29', '894.23', '911.84', '876.62', '903.17', '885.29', '907.64', '884.34']\n",
      "['캐나다', '2019.10.28', '896.52', '914.18', '878.86', '905.48', '887.56', '909.96', '886.60']\n",
      "['캐나다', '2019.10.25', '898.97', '916.67', '881.27', '907.95', '889.99', '912.45', '889.03']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "URL = 'http://finance.naver.com/marketindex/exchangeDailyQuote.nhn?marketindexCd=FX_'\n",
    "keys = ['USDKRW', 'JPYKRW', 'EURKRW', 'CNYKRW', 'CADKRW', 'AUDKRW']\n",
    "\n",
    "def country():\n",
    "    country_name_list = []\n",
    "    for key in keys:\n",
    "        country_url = 'https://finance.naver.com/marketindex/exchangeDetail.nhn?marketindexCd=FX_'\n",
    "        tempUrl = country_url + key\n",
    "        req = requests.get(tempUrl)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        country_names = soup.select('#container > div.h_company > h2 ')\n",
    "        for country_name in country_names:\n",
    "#             print(country_name.text)\n",
    "            country_name = country_name.text.strip()\n",
    "            country_name_list.append(country_name)\n",
    "    return country_name_list\n",
    "\n",
    "def cad(soup, country_name):\n",
    "#     url = URL + keys[0]\n",
    "#     for i in range(1, 5):\n",
    "#         usd_url = url + '&page=' + str(i)\n",
    "#         req = requests.get(usd_url)\n",
    "#         soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "#         sleep(1)\n",
    "    country()\n",
    "    cad_list = []\n",
    "    tr_list = soup.select('body > div > table > tbody > tr')\n",
    "    for tr in tr_list:\n",
    "        cad_date = tr.find('td', {'class' : 'date'}).text\n",
    "        cad_exchange = tr.find('td', {'class' : 'num'}).text\n",
    "        for cad_buy_cash in tr.select('td:nth-child(4)'):\n",
    "            cad_buy_cash = cad_buy_cash.text\n",
    "        for cad_sell_cash in tr.select('td:nth-child(5)'):\n",
    "            cad_sell_cash = cad_sell_cash.text\n",
    "        for cad_send_money in tr.select('td:nth-child(6)'):\n",
    "            cad_send_money = cad_send_money.text\n",
    "        for cad_get_money in tr.select('td:nth-child(7)'):\n",
    "            cad_get_money = cad_get_money.text\n",
    "        for cad_buy_tc in tr.select('td:nth-child(8)'):\n",
    "            cad_buy_tc = cad_buy_tc.text.strip()\n",
    "        for cad_sell_check in tr.select('td:nth-child(9)'):\n",
    "            cad_sell_check = cad_sell_check.text.strip()\n",
    "        cad_list.append([country_name, cad_date, cad_exchange, cad_buy_cash, cad_sell_cash, cad_send_money, cad_get_money, cad_buy_tc, cad_sell_check])\n",
    "\n",
    "    return cad_list\n",
    "\n",
    "def toCSV(cad_whole_list):\n",
    "    dt = datetime.datetime.now()\n",
    "    file = open('exchange '+dt.strftime('%Y_%m_%d')+'.csv', 'w', encoding='cp949', newline='') #usd.csv로 바꿀것\n",
    "    csvfile = csv.writer(file)\n",
    "    csvfile.writerow(['country', 'date', 'exchange', 'buying cash', 'selling cash', 'sending money', 'getting money', 'buying TC', 'selling check'])\n",
    "    for row in cad_whole_list:\n",
    "        csvfile.writerow(row)\n",
    "    file.close()\n",
    "\n",
    "def toCSV_a(cad_whole_list):\n",
    "    dt = datetime.datetime.now()\n",
    "    with open('test '+dt.strftime('%Y_%m_%d')+'.csv', 'w', encoding='cp949', newline='') as file: #usd.csv로 바꿀것\n",
    "        csvfile = csv.writer(file)\n",
    "        csvfile.writerow(['country', 'date', 'exchange', 'buying cash', 'selling cash', 'sending money', 'getting money', 'buying TC', 'selling check'])\n",
    "        csvfile.writerow(cad_whole_list)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     req = requests.get(URL + keys[0]) #0으로 바꿀것\n",
    "#     soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "    country_name = country()\n",
    "\n",
    "    cad_whole_list = []\n",
    "    for i in range(1,3):\n",
    "        usd_url = URL + keys[4] + '&page=' + str(i)\n",
    "        req = requests.get(usd_url)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        sleep(1)\n",
    "        cad_whole_list += cad(soup, country_name[4])\n",
    "#         usd_whole_list += usd(soup, keys[0]) #USDKRW로 출력\n",
    "\n",
    "    for item in cad_whole_list:\n",
    "        print(item)\n",
    "\n",
    "    toCSV(cad_whole_list)\n",
    "\n",
    "#crawling_beautifulsoup에서 usd_get_one_data 함수 가져올 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
