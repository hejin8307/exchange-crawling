{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "URL = 'http://finance.naver.com/marketindex/exchangeDailyQuote.nhn?marketindexCd=FX_'\n",
    "keys = ['USDKRW', 'JPYKRW', 'EURKRW', 'CNYKRW', 'CADKRW', 'AUDKRW']\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(',', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def country():\n",
    "    country_name_list = []\n",
    "    for key in keys:\n",
    "        country_url = 'https://finance.naver.com/marketindex/exchangeDetail.nhn?marketindexCd=FX_'\n",
    "        tempUrl = country_url + key\n",
    "        req = requests.get(tempUrl)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        country_names = soup.select('#container > div.h_company > h2 ')\n",
    "        for country_name in country_names:\n",
    "            country_name = country_name.text.strip()\n",
    "            country_name_list.append(country_name)\n",
    "    return country_name_list\n",
    "\n",
    "def get_exchange(country_name):\n",
    "    country()\n",
    "    exchange_list = []\n",
    "    tr_list = soup.select('body > div > table > tbody > tr')\n",
    "    for tr in tr_list:\n",
    "        date = tr.find('td', {'class' : 'date'}).text\n",
    "        exchange = tr.find('td', {'class' : 'num'}).text\n",
    "        exchange = clean_text(exchange)\n",
    "        for buy_cash in tr.select('td:nth-child(4)'):\n",
    "            buy_cash = clean_text(buy_cash.text)\n",
    "        for sell_cash in tr.select('td:nth-child(5)'):\n",
    "            sell_cash = clean_text(sell_cash.text)\n",
    "        for send_money in tr.select('td:nth-child(6)'):\n",
    "            send_money = clean_text(send_money.text)\n",
    "        for get_money in tr.select('td:nth-child(7)'):\n",
    "            get_money = clean_text(get_money.text)\n",
    "        for buy_tc in tr.select('td:nth-child(8)'):\n",
    "            buy_tc = clean_text(buy_tc.text.strip())\n",
    "        for sell_check in tr.select('td:nth-child(9)'):\n",
    "            sell_check = clean_text(sell_check.text.strip())\n",
    "        exchange_list.append([country_name, date, exchange, buy_cash, sell_cash, send_money, get_money, buy_tc, sell_check])\n",
    "    return exchange_list[0]\n",
    "\n",
    "def toCSV(whole_list):\n",
    "    dt = datetime.datetime.now()\n",
    "    with open('exchange'+dt.strftime('%Y_%m_%d')+'.csv', 'w', encoding='utf-8', newline='') as file: #cp949 csv 한글 안 깨지는 것\n",
    "        csvfile = csv.writer(file)\n",
    "        csvfile.writerow(['country', 'date', 'exchange', 'buying_cash', 'selling_cash', 'sending_money', 'getting_money', 'buying_TC', 'selling_check'])\n",
    "        csvfile.writerow(whole_list)\n",
    "    file.close()\n",
    "    \n",
    "def toCSV_b(whole_list):\n",
    "    dt = datetime.datetime.now()\n",
    "    with open('exchange'+dt.strftime('%Y_%m_%d')+'.csv', 'a', encoding='utf-8', newline='') as file:\n",
    "        csvfile = csv.writer(file) \n",
    "        csvfile.writerow(whole_list)\n",
    "    file.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    country_name = country()\n",
    "\n",
    "    usd_new_data = []\n",
    "    jpy_new_data = []\n",
    "    eur_new_data = []\n",
    "    cny_new_data = []\n",
    "    cad_new_data = []\n",
    "    aud_new_data = []\n",
    "    \n",
    "    usd_url = URL + keys[0] + '&page=1'\n",
    "    req = requests.get(usd_url)\n",
    "    soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "    usd_new_data = get_exchange(country_name[0])\n",
    "    \n",
    "    jpy_url = URL + keys[1] + '&page1'\n",
    "    req = requests.get(jpy_url)\n",
    "    jpy_new_data = get_exchange(country_name[1])\n",
    "    \n",
    "    eur_url = URL + keys[2] + '&page1'\n",
    "    req = requests.get(eur_url)\n",
    "    eur_new_data = get_exchange(country_name[2])\n",
    "    \n",
    "    cny_url = URL + keys[3] + '&page1'\n",
    "    req = requests.get(cny_url)\n",
    "    cny_new_data = get_exchange(country_name[3])\n",
    "    \n",
    "    cad_url = URL + keys[4] + '&page1'\n",
    "    req = requests.get(cad_url)\n",
    "    cad_new_data = get_exchange(country_name[4])\n",
    "    \n",
    "    aud_url = URL + keys[5] + '&page1'\n",
    "    req = requests.get(aud_url)\n",
    "    aud_new_data = get_exchange(country_name[5])\n",
    "\n",
    "    toCSV(usd_new_data)\n",
    "    toCSV_b(jpy_new_data)\n",
    "    toCSV_b(eur_new_data)\n",
    "    toCSV_b(cny_new_data)\n",
    "    toCSV_b(cad_new_data)\n",
    "    toCSV_b(aud_new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
