{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "URL = 'http://finance.naver.com/marketindex/exchangeDailyQuote.nhn?marketindexCd=FX_'\n",
    "keys = ['USDKRW', 'JPYKRW', 'EURKRW', 'CNYKRW', 'CADKRW', 'AUDKRW']\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(',', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "def country():\n",
    "    country_name_list = []\n",
    "    for key in keys:\n",
    "        country_url = 'https://finance.naver.com/marketindex/exchangeDetail.nhn?marketindexCd=FX_'\n",
    "        tempUrl = country_url + key\n",
    "        req = requests.get(tempUrl)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        country_names = soup.select('#container > div.h_company > h2 ')\n",
    "        for country_name in country_names:\n",
    "#             print(country_name.text)\n",
    "            country_name = country_name.text.strip()\n",
    "            country_name_list.append(country_name)\n",
    "    return country_name_list\n",
    "\n",
    "def usd(soup, country_name):\n",
    "#     url = URL + keys[0]\n",
    "#     for i in range(1, 5):\n",
    "#         usd_url = url + '&page=' + str(i)\n",
    "#         req = requests.get(usd_url)\n",
    "#         soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "#         sleep(1)\n",
    "    country()\n",
    "    usd_list = []\n",
    "    tr_list = soup.select('body > div > table > tbody > tr')\n",
    "    for tr in tr_list:\n",
    "        usd_date = tr.find('td', {'class' : 'date'}).text\n",
    "        usd_exchange = tr.find('td', {'class' : 'num'}).text\n",
    "        usd_exchange = clean_text(usd_exchange)\n",
    "        for usd_buy_cash in tr.select('td:nth-child(4)'):\n",
    "            usd_buy_cash = clean_text(usd_buy_cash.text)\n",
    "        for usd_sell_cash in tr.select('td:nth-child(5)'):\n",
    "            usd_sell_cash = clean_text(usd_sell_cash.text)\n",
    "        for usd_send_money in tr.select('td:nth-child(6)'):\n",
    "            usd_send_money = clean_text(usd_send_money.text)\n",
    "        for usd_get_money in tr.select('td:nth-child(7)'):\n",
    "            usd_get_money = clean_text(usd_get_money.text)\n",
    "        for usd_buy_tc in tr.select('td:nth-child(8)'):\n",
    "            usd_buy_tc = clean_text(usd_buy_tc.text.strip())\n",
    "        for usd_sell_check in tr.select('td:nth-child(9)'):\n",
    "            usd_sell_check = clean_text(usd_sell_check.text.strip())\n",
    "        usd_list.append([country_name, usd_date, usd_exchange, usd_buy_cash, usd_sell_cash, usd_send_money, usd_get_money, usd_buy_tc, usd_sell_check])\n",
    "\n",
    "    return usd_list\n",
    "\n",
    "\n",
    "\n",
    "def jpy(soup, country_name):\n",
    "#     url = URL + keys[0]\n",
    "#     for i in range(1, 5):\n",
    "#         usd_url = url + '&page=' + str(i)\n",
    "#         req = requests.get(usd_url)\n",
    "#         soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "#         sleep(1)\n",
    "    country()\n",
    "    jpy_list = []\n",
    "    tr_list = soup.select('body > div > table > tbody > tr')\n",
    "    for tr in tr_list:\n",
    "        jpy_date = tr.find('td', {'class' : 'date'}).text\n",
    "        jpy_exchange = tr.find('td', {'class' : 'num'}).text\n",
    "        jpy_exchange = clean_text(jpy_exchange)\n",
    "        for jpy_buy_cash in tr.select('td:nth-child(4)'):\n",
    "            jpy_buy_cash = clean_text(jpy_buy_cash.text)\n",
    "        for jpy_sell_cash in tr.select('td:nth-child(5)'):\n",
    "            jpy_sell_cash = clean_text(jpy_sell_cash.text)\n",
    "        for jpy_send_money in tr.select('td:nth-child(6)'):\n",
    "            jpy_send_money = clean_text(jpy_send_money.text)\n",
    "        for jpy_get_money in tr.select('td:nth-child(7)'):\n",
    "            jpy_get_money = clean_text(jpy_get_money.text)\n",
    "        for jpy_buy_tc in tr.select('td:nth-child(8)'):\n",
    "            jpy_buy_tc = clean_text(jpy_buy_tc.text.strip())\n",
    "        for jpy_sell_check in tr.select('td:nth-child(9)'):\n",
    "            jpy_sell_check = clean_text(jpy_sell_check.text.strip())\n",
    "        jpy_list.append([country_name, jpy_date, jpy_exchange, jpy_buy_cash, jpy_sell_cash, jpy_send_money, jpy_get_money, jpy_buy_tc, jpy_sell_check])\n",
    "\n",
    "    return jpy_list\n",
    "\n",
    "def eur(soup, country_name):\n",
    "#     url = URL + keys[0]\n",
    "#     for i in range(1, 5):\n",
    "#         usd_url = url + '&page=' + str(i)\n",
    "#         req = requests.get(usd_url)\n",
    "#         soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "#         sleep(1)\n",
    "    country()\n",
    "    eur_list = []\n",
    "    tr_list = soup.select('body > div > table > tbody > tr')\n",
    "    for tr in tr_list:\n",
    "        eur_date = tr.find('td', {'class' : 'date'}).text\n",
    "        eur_exchange = tr.find('td', {'class' : 'num'}).text\n",
    "        eur_exchange = clean_text(eur_exchange)\n",
    "        for eur_buy_cash in tr.select('td:nth-child(4)'):\n",
    "            eur_buy_cash = clean_text(eur_buy_cash.text)\n",
    "        for eur_sell_cash in tr.select('td:nth-child(5)'):\n",
    "            eur_sell_cash = clean_text(eur_sell_cash.text)\n",
    "        for eur_send_money in tr.select('td:nth-child(6)'):\n",
    "            eur_send_money = clean_text(eur_send_money.text)\n",
    "        for eur_get_money in tr.select('td:nth-child(7)'):\n",
    "            eur_get_money = clean_text(eur_get_money.text)\n",
    "        for eur_buy_tc in tr.select('td:nth-child(8)'):\n",
    "            eur_buy_tc = clean_text(eur_buy_tc.text.strip())\n",
    "        for eur_sell_check in tr.select('td:nth-child(9)'):\n",
    "            eur_sell_check = clean_text(eur_sell_check.text.strip())\n",
    "        eur_list.append([country_name, eur_date, eur_exchange, eur_buy_cash, eur_sell_cash, eur_send_money, eur_get_money, eur_buy_tc, eur_sell_check])\n",
    "\n",
    "    return eur_list\n",
    "\n",
    "def cny(soup, country_name):\n",
    "#     url = URL + keys[0]\n",
    "#     for i in range(1, 5):\n",
    "#         usd_url = url + '&page=' + str(i)\n",
    "#         req = requests.get(usd_url)\n",
    "#         soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "#         sleep(1)\n",
    "    country()\n",
    "    cny_list = []\n",
    "    tr_list = soup.select('body > div > table > tbody > tr')\n",
    "    for tr in tr_list:\n",
    "        cny_date = tr.find('td', {'class' : 'date'}).text\n",
    "        cny_exchange = tr.find('td', {'class' : 'num'}).text\n",
    "        cny_exchange = clean_text(cny_exchange)\n",
    "        for cny_buy_cash in tr.select('td:nth-child(4)'):\n",
    "            cny_buy_cash = clean_text(cny_buy_cash.text)\n",
    "        for cny_sell_cash in tr.select('td:nth-child(5)'):\n",
    "            cny_sell_cash = clean_text(cny_sell_cash.text)\n",
    "        for cny_send_money in tr.select('td:nth-child(6)'):\n",
    "            cny_send_money = clean_text(cny_send_money.text)\n",
    "        for cny_get_money in tr.select('td:nth-child(7)'):\n",
    "            cny_get_money = clean_text(cny_get_money.text)\n",
    "        for cny_buy_tc in tr.select('td:nth-child(8)'):\n",
    "            cny_buy_tc = clean_text(cny_buy_tc.text.strip())\n",
    "        for cny_sell_check in tr.select('td:nth-child(9)'):\n",
    "            cny_sell_check = clean_text(cny_sell_check.text.strip())\n",
    "        cny_list.append([country_name, cny_date, cny_exchange, cny_buy_cash, cny_sell_cash, cny_send_money, cny_get_money, cny_buy_tc, cny_sell_check])\n",
    "\n",
    "    return cny_list\n",
    "\n",
    "def cad(soup, country_name):\n",
    "#     url = URL + keys[0]\n",
    "#     for i in range(1, 5):\n",
    "#         usd_url = url + '&page=' + str(i)\n",
    "#         req = requests.get(usd_url)\n",
    "#         soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "#         sleep(1)\n",
    "    country()\n",
    "    cad_list = []\n",
    "    tr_list = soup.select('body > div > table > tbody > tr')\n",
    "    for tr in tr_list:\n",
    "        cad_date = tr.find('td', {'class' : 'date'}).text\n",
    "        cad_exchange = tr.find('td', {'class' : 'num'}).text\n",
    "        cad_exchange = clean_text(cad_exchange)\n",
    "        for cad_buy_cash in tr.select('td:nth-child(4)'):\n",
    "            cad_buy_cash = clean_text(cad_buy_cash.text)\n",
    "        for cad_sell_cash in tr.select('td:nth-child(5)'):\n",
    "            cad_sell_cash = clean_text(cad_sell_cash.text)\n",
    "        for cad_send_money in tr.select('td:nth-child(6)'):\n",
    "            cad_send_money = clean_text(cad_send_money.text)\n",
    "        for cad_get_money in tr.select('td:nth-child(7)'):\n",
    "            cad_get_money = clean_text(cad_get_money.text)\n",
    "        for cad_buy_tc in tr.select('td:nth-child(8)'):\n",
    "            cad_buy_tc = clean_text(cad_buy_tc.text.strip())\n",
    "        for cad_sell_check in tr.select('td:nth-child(9)'):\n",
    "            cad_sell_check = clean_text(cad_sell_check.text.strip())\n",
    "        cad_list.append([country_name, cad_date, cad_exchange, cad_buy_cash, cad_sell_cash, cad_send_money, cad_get_money, cad_buy_tc, cad_sell_check])\n",
    "\n",
    "    return cad_list\n",
    "\n",
    "def aud(soup, country_name):\n",
    "#     url = URL + keys[0]\n",
    "#     for i in range(1, 5):\n",
    "#         usd_url = url + '&page=' + str(i)\n",
    "#         req = requests.get(usd_url)\n",
    "#         soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "#         sleep(1)\n",
    "    country()\n",
    "    aud_list = []\n",
    "    tr_list = soup.select('body > div > table > tbody > tr')\n",
    "    for tr in tr_list:\n",
    "        aud_date = tr.find('td', {'class' : 'date'}).text\n",
    "        aud_exchange = tr.find('td', {'class' : 'num'}).text\n",
    "        aud_exchange = clean_text(aud_exchange)\n",
    "        for aud_buy_cash in tr.select('td:nth-child(4)'):\n",
    "            aud_buy_cash = clean_text(aud_buy_cash.text)\n",
    "        for aud_sell_cash in tr.select('td:nth-child(5)'):\n",
    "            aud_sell_cash = clean_text(aud_sell_cash.text)\n",
    "        for aud_send_money in tr.select('td:nth-child(6)'):\n",
    "            aud_send_money = clean_text(aud_send_money.text)\n",
    "        for aud_get_money in tr.select('td:nth-child(7)'):\n",
    "            aud_get_money = clean_text(aud_get_money.text)\n",
    "        for aud_buy_tc in tr.select('td:nth-child(8)'):\n",
    "            aud_buy_tc = clean_text(aud_buy_tc.text.strip())\n",
    "        for aud_sell_check in tr.select('td:nth-child(9)'):\n",
    "            aud_sell_check = clean_text(aud_sell_check.text.strip())\n",
    "        aud_list.append([country_name, aud_date, aud_exchange, aud_buy_cash, aud_sell_cash, aud_send_money, aud_get_money, aud_buy_tc, aud_sell_check])\n",
    "\n",
    "    return aud_list\n",
    "\n",
    "def toCSV(whole_list):\n",
    "    dt = datetime.datetime.now()\n",
    "    file = open('exchange'+dt.strftime('%Y_%m_%d')+'.csv', 'w', encoding='UTF-8', newline='') #usd.csv로 바꿀것\n",
    "    csvfile = csv.writer(file)\n",
    "    csvfile.writerow(['country', 'date', 'exchange', 'buying_cash', 'selling_cash', 'sending_money', 'getting_money', 'buying_TC', 'selling_check'])\n",
    "    for row in whole_list:\n",
    "        csvfile.writerow(row)\n",
    "    file.close()\n",
    "    \n",
    "def toCSV_a(whole_list):\n",
    "    dt = datetime.datetime.now()\n",
    "    file = open('exchange'+dt.strftime('%Y_%m_%d')+'.csv', 'a', encoding='UTF-8', newline='') #usd.csv로 바꿀것\n",
    "    csvfile = csv.writer(file)\n",
    "#     csvfile.writerow(['country', 'date', 'exchange', 'buying cash', 'selling cash', 'sending money', 'getting money', 'buying TC', 'selling check'])\n",
    "    for row in whole_list:\n",
    "        csvfile.writerow(row)\n",
    "    file.close()\n",
    "\n",
    "def toCSV_new_a(whole_list):\n",
    "    dt = datetime.datetime.now()\n",
    "    with open('exchange'+dt.strftime('%Y_%m_%d')+'.csv', 'a', encoding='UTF-8', newline='') as file: #usd.csv로 바꿀것\n",
    "        csvfile = csv.writer(file)\n",
    "#         csvfile.writerow(['country', 'date', 'exchange', 'buying cash', 'selling cash', 'sending money', 'getting money', 'buying TC', 'selling check'])\n",
    "        csvfile.writerow(whole_list)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     req = requests.get(URL + keys[0]) #0으로 바꿀것\n",
    "#     soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "    country_name = country()\n",
    "\n",
    "    usd_whole_list = []\n",
    "    jpy_whole_list = []\n",
    "    eur_whole_list = []\n",
    "    cny_whole_list = []\n",
    "    cad_whole_list = []\n",
    "    aud_whole_list = []\n",
    "    \n",
    "    for i in range(1,389): #389\n",
    "        usd_url = URL + keys[0] + '&page=' + str(i)\n",
    "        req = requests.get(usd_url)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        sleep(1)\n",
    "        usd_whole_list += usd(soup, country_name[0])\n",
    "#         usd_whole_list += usd(soup, keys[0]) #USDKRW로 출력\n",
    "\n",
    "    \n",
    "    for i in range(1,389):\n",
    "        jpy_url = URL + keys[1] + '&page=' + str(i)\n",
    "        req = requests.get(jpy_url)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        sleep(1)\n",
    "        jpy_whole_list += jpy(soup, country_name[1])\n",
    "        \n",
    "    \n",
    "    for i in range(1,389):\n",
    "        eur_url = URL + keys[2] + '&page=' + str(i)\n",
    "        req = requests.get(eur_url)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        sleep(1)\n",
    "        eur_whole_list += eur(soup, country_name[2])\n",
    "        \n",
    "    \n",
    "    for i in range(1,389):\n",
    "        cny_url = URL + keys[3] + '&page=' + str(i)\n",
    "        req = requests.get(cny_url)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        sleep(1)\n",
    "        cny_whole_list += cny(soup, country_name[3])\n",
    "        \n",
    "    \n",
    "    for i in range(1,389):\n",
    "        usd_url = URL + keys[4] + '&page=' + str(i)\n",
    "        req = requests.get(usd_url)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        sleep(1)\n",
    "        cad_whole_list += cad(soup, country_name[4])\n",
    "        \n",
    "    \n",
    "    for i in range(1,389):\n",
    "        aud_url = URL + keys[5] + '&page=' + str(i)\n",
    "        req = requests.get(aud_url)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        sleep(1)\n",
    "        aud_whole_list += aud(soup, country_name[5])\n",
    "    \n",
    "\n",
    "#     for item in usd_whole_list:\n",
    "#         print(item)\n",
    "        \n",
    "#     for item in jpy_whole_list:\n",
    "#         print(item)\n",
    "        \n",
    "#     for item in eur_whole_list:\n",
    "#         print(item)\n",
    "        \n",
    "#     for item in cny_whole_list:\n",
    "#         print(item)\n",
    "        \n",
    "#     for item in cad_whole_list:\n",
    "#         print(item)\n",
    "        \n",
    "#     for item in aud_whole_list:\n",
    "#         print(item)\n",
    "\n",
    "    toCSV(usd_whole_list)\n",
    "    toCSV_a(jpy_whole_list)\n",
    "    toCSV_a(eur_whole_list)\n",
    "    toCSV_a(cny_whole_list)\n",
    "    toCSV_a(cad_whole_list)\n",
    "    toCSV_a(aud_whole_list)\n",
    "\n",
    "#for문 범위 수정하고 csv 파일명 수정\n",
    "#crawling_beautifulsoup에서 usd_get_one_data 함수 가져올 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
