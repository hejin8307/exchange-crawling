{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "URL = 'http://finance.naver.com/marketindex/exchangeDailyQuote.nhn?marketindexCd=FX_'\n",
    "keys = ['USDKRW', 'JPYKRW', 'EURKRW', 'CNYKRW', 'CADKRW', 'AUDKRW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country():\n",
    "    country_name_list = []\n",
    "    for key in keys:\n",
    "        country_url = 'https://finance.naver.com/marketindex/exchangeDetail.nhn?marketindexCd=FX_'\n",
    "        tempUrl = country_url + key\n",
    "        req = requests.get(tempUrl)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        country_names = soup.select('#container > div.h_company > h2 ')\n",
    "        for country_name in country_names:\n",
    "#             print(country_name.text)\n",
    "            country_name = country_name.text.strip()\n",
    "            country_name_list.append(country_name)\n",
    "    return country_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jpy(soup, country_name):\n",
    "#     url = URL + keys[0]\n",
    "#     for i in range(1, 5):\n",
    "#         usd_url = url + '&page=' + str(i)\n",
    "#         req = requests.get(usd_url)\n",
    "#         soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "#         sleep(1)\n",
    "    country()\n",
    "    jpy_list = []\n",
    "    tr_list = soup.select('body > div > table > tbody > tr')\n",
    "    for tr in tr_list:\n",
    "        jpy_date = tr.find('td', {'class' : 'date'}).text\n",
    "        jpy_exchange = tr.find('td', {'class' : 'num'}).text\n",
    "        for jpy_buy_cash in tr.select('td:nth-child(4)'):\n",
    "            jpy_buy_cash = jpy_buy_cash.text\n",
    "        for jpy_sell_cash in tr.select('td:nth-child(5)'):\n",
    "            jpy_sell_cash = jpy_sell_cash.text\n",
    "        for jpy_send_money in tr.select('td:nth-child(6)'):\n",
    "            jpy_send_money = jpy_send_money.text\n",
    "        for jpy_get_money in tr.select('td:nth-child(7)'):\n",
    "            jpy_get_money = jpy_get_money.text\n",
    "        for jpy_buy_tc in tr.select('td:nth-child(8)'):\n",
    "            jpy_buy_tc = jpy_buy_tc.text.strip()\n",
    "        for jpy_sell_check in tr.select('td:nth-child(9)'):\n",
    "            jpy_sell_check = jpy_sell_check.text.strip()\n",
    "        jpy_list.append([country_name, jpy_date, jpy_exchange, jpy_buy_cash, jpy_sell_cash, jpy_send_money, jpy_get_money, jpy_buy_tc, jpy_sell_check])\n",
    "\n",
    "    return jpy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toCSV(jpy_whole_list):\n",
    "    dt = datetime.datetime.now()\n",
    "    file = open('jpy '+dt.strftime('%Y_%m_%d')+'.csv', 'w', encoding='cp949', newline='') #usd.csv로 바꿀것\n",
    "    csvfile = csv.writer(file)\n",
    "    csvfile.writerow(['country', 'date', 'exchange', 'buying cash', 'selling cash', 'sending money', 'getting money', 'buying TC', 'selling check'])\n",
    "    for row in jpy_whole_list:\n",
    "        csvfile.writerow(row)\n",
    "    file.close()\n",
    "\n",
    "def toCSV_a(jpy_whole_list):\n",
    "    dt = datetime.datetime.now()\n",
    "    with open('jpy '+dt.strftime('%Y_%m_%d')+'.csv', 'w', encoding='cp949', newline='') as file:\n",
    "        csvfile = csv.writer(file)\n",
    "#         csvfile.writerow(['country', 'date', 'exchange', 'buying cash', 'selling cash', 'sending money', 'getting money', 'buying TC', 'selling check'])\n",
    "        csvfile.writerow(jpy_whole_list)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['일본', '2019.11.21', '1,084.07', '1,103.04', '1,065.10', '1,094.69', '1,073.45', '1,094.91', '1,072.95']\n",
      "['일본', '2019.11.20', '1,079.35', '1,098.23', '1,060.47', '1,089.92', '1,068.78', '1,090.14', '1,068.28']\n",
      "['일본', '2019.11.19', '1,072.05', '1,090.81', '1,053.29', '1,082.55', '1,061.55', '1,082.77', '1,061.05']\n",
      "['일본', '2019.11.18', '1,068.82', '1,087.52', '1,050.12', '1,079.29', '1,058.35', '1,079.50', '1,057.86']\n",
      "['일본', '2019.11.15', '1,074.14', '1,092.93', '1,055.35', '1,084.66', '1,063.62', '1,084.88', '1,063.12']\n",
      "['일본', '2019.11.14', '1,077.36', '1,096.21', '1,058.51', '1,087.91', '1,066.81', '1,088.13', '1,066.31']\n",
      "['일본', '2019.11.13', '1,073.67', '1,092.45', '1,054.89', '1,084.19', '1,063.15', '1,084.40', '1,062.65']\n",
      "['일본', '2019.11.12', '1,065.72', '1,084.37', '1,047.07', '1,076.16', '1,055.28', '1,076.37', '1,054.79']\n",
      "['일본', '2019.11.11', '1,069.51', '1,088.22', '1,050.80', '1,079.99', '1,059.03', '1,080.20', '1,058.53']\n",
      "['일본', '2019.11.08', '1,058.48', '1,077.00', '1,039.96', '1,068.85', '1,048.11', '1,069.06', '1,047.62']\n",
      "['일본', '2019.11.07', '1,059.53', '1,078.07', '1,040.99', '1,069.91', '1,049.15', '1,070.12', '1,048.66']\n",
      "['일본', '2019.11.06', '1,062.70', '1,081.29', '1,044.11', '1,073.11', '1,052.29', '1,073.32', '1,051.80']\n",
      "['일본', '2019.11.05', '1,062.11', '1,080.69', '1,043.53', '1,072.51', '1,051.71', '1,072.73', '1,051.22']\n",
      "['일본', '2019.11.04', '1,069.98', '1,088.70', '1,051.26', '1,080.46', '1,059.50', '1,080.67', '1,059.01']\n",
      "['일본', '2019.11.01', '1,080.26', '1,099.16', '1,061.36', '1,090.84', '1,069.68', '1,091.06', '1,069.18']\n",
      "['일본', '2019.10.31', '1,078.90', '1,097.78', '1,060.02', '1,089.47', '1,068.33', '1,089.68', '1,067.83']\n",
      "['일본', '2019.10.30', '1,071.71', '1,090.46', '1,052.96', '1,082.21', '1,061.21', '1,082.42', '1,060.72']\n",
      "['일본', '2019.10.29', '1,072.69', '1,091.46', '1,053.92', '1,083.20', '1,062.18', '1,083.41', '1,061.69']\n",
      "['일본', '2019.10.28', '1,076.67', '1,095.51', '1,057.83', '1,087.22', '1,066.12', '1,087.43', '1,065.62']\n",
      "['일본', '2019.10.25', '1,081.34', '1,100.26', '1,062.42', '1,091.93', '1,070.75', '1,092.15', '1,070.25']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     req = requests.get(URL + keys[0]) #0으로 바꿀것\n",
    "#     soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "    country_name = country()\n",
    "\n",
    "    jpy_whole_list = []\n",
    "    for i in range(1,3):\n",
    "        jpy_url = URL + keys[1] + '&page=' + str(i)\n",
    "        req = requests.get(jpy_url)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        sleep(1)\n",
    "        jpy_whole_list += jpy(soup, country_name[1])\n",
    "#         usd_whole_list += usd(soup, keys[0]) #USDKRW로 출력\n",
    "\n",
    "    for item in jpy_whole_list:\n",
    "        print(item)\n",
    "\n",
    "#     toCSV(jpy_whole_list)\n",
    "\n",
    "#crawling_beautifulsoup에서 usd_get_one_data 함수 가져올 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
